{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula-10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7F8w49vB7sT0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.datasets.samples_generator import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIW86R6n5VcS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classificação com NN\n",
        "\n",
        "Com aquilo que aprendemos, vamos tentar resolver um problema de classificação binária. Veja como é simples apenas modificando um pouco a estrutura de nossa rede."
      ]
    },
    {
      "metadata": {
        "id": "z1tkxyxr8AC7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3rMv-VN8GF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples = 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xo4urCsr8JVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fh4RMRVd88y2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rh3KN6pF9G4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9BLYmxW9HPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_scaler = StandardScaler()\n",
        "X_train = X_scaler.fit_transform(X_train)\n",
        "X_test = X_scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qa9DZA5-9bXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XwcBMy_1-XX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos criar nossa função `build_model` verifique que agora temos um problema de classificação binário, sendo assim, iremos utilizar como função de loss a `binary_crossentropy`."
      ]
    },
    {
      "metadata": {
        "id": "FrVE4GF---z7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(20, input_dim = 20, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(40, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZSg8k-GxCvPO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verifique que modificamos também nossa função de otimização e métrica. Para entender melhor como o algoritmo de otimização \"adam\" funciona, veja o seguinte [artigo](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)."
      ]
    },
    {
      "metadata": {
        "id": "E3JK7QyjBKME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos modificar nossa função para plotar os gráficos"
      ]
    },
    {
      "metadata": {
        "id": "rzEsJ-5vBOWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  plt.figure(figsize = (15, 10))\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(history.epoch, np.array(history.history['acc']), label='Train Acc')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_acc']), label = 'Val Acc')\n",
        "  plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yktJVASA_4jc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = 5, validation_split = 0.2, verbose = False)\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFen-axRAJvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[loss, acc] = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Acc: {:.4f}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOibRRZ3MLuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_O37_RoM_V2g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos plotar nossa matriz de confusão:"
      ]
    },
    {
      "metadata": {
        "id": "AJHdQyJqNhdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_preds = model.predict(X_test).flatten()\n",
        "test_preds_bin = (test_preds > 0.5)\n",
        "test_preds_bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSIWc1ycNDGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm  = confusion_matrix(y_test, test_preds_bin)\n",
        "\n",
        "sns.heatmap(cm, annot = True, fmt='g', cmap = 'winter')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t0wTyaGJPwWw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Curva ROC\n",
        "\n",
        "A Curva de operação do receptor (*Receiver Operationg Characteristic*)  é uma representação gráfica que ilustra o desempenho (ou performance) de um sistema classificador binário e como o seu limiar de discriminação é variado. [Wikipedia](https://pt.wikipedia.org/wiki/Caracter%C3%ADstica_de_Opera%C3%A7%C3%A3o_do_Receptor)\n",
        "\n",
        " ![PIC6](https://ncss-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/ROC-Curves-Empirical-19.png)"
      ]
    },
    {
      "metadata": {
        "id": "58gomEGBTiu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Sensitivity\n",
        "\n",
        "Também chamada de *true positive rate*, *recall* ou *probabilidade de detecção*. Mede a proporção de positivos realmente detectados como positivos.\n",
        "\n",
        "$$\n",
        "TPR = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "#### Specificity\n",
        "\n",
        "Também chamada de *true negative rate*, mede a proporção de negativos realmente detectados como negativos.\n",
        "\n",
        "$$\n",
        "TNR = \\frac{TN}{TN + FP}\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "akRPphWxUwmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtendo os valores:"
      ]
    },
    {
      "metadata": {
        "id": "dUu8Jbi9OCdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, test_preds)\n",
        "auc_calc = auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "93XMrXZYVpb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 10))\n",
        "plt.plot(fpr, tpr, label='Modelo (area = {:.3f})'.format(auc_calc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='best')\n",
        "plt.plot([0, 1], [0, 1], 'k--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-e6cElBBUUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Desafio\n",
        "\n",
        "Utilize o dataset fornecido a tente criar um modelo capaz de classificar os dados não conhecidos pela coluna diagnóstico."
      ]
    },
    {
      "metadata": {
        "id": "HCY7FdGhB4vo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://github.com/pgiaeinstein/aula-09/raw/master/df_map.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBt5LzOeCGXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfqErYxoCLbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "notebook_seed = 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = notebook_seed)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6aE5tj1g3f_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_LHnTgohR7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(20, input_dim = 20, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(40, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ll6EvRmFg-Zt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DioZLvCXiqon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiC5dg38i1fY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A42ibvifjEyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2UmZx2fgjUSI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GRxtSs7whfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Trabalhando com arquivos DICOM\n",
        "\n",
        "## O que é DICOM?\n",
        "\n",
        "- DICOM - Digital Imaging and Communications in Medicine;\n",
        "\n",
        "- Conjunto de normas para tratamento, armazenamento e transmissão de informação médica (PROTOCOLO);\n",
        " - Padroniza a formatação das imagens diagnósticas como tomografias, ressonâncias magnéticas, radiografias, ultrassonografias, etc...;\n",
        "  - Permite que imagens médicas e informações associadas sejam trocadas entre equipamentos de diagnóstico geradores de imagens, computadores e hospitais, ou seja, estabelece uma linguagem comum entre os equipamentos de diferentes marcas.\n",
        "\n",
        "[Wikipedia](https://pt.wikipedia.org/wiki/DICOM)"
      ]
    },
    {
      "metadata": {
        "id": "BPKWuCjuzZ0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Protocolo?\n",
        "\n",
        "- Convenção que controla e possibilita uma conexão, comunicação, transferência de dados entre dois sistemas computacionais.\n",
        "\n",
        "- Define regras de sintaxe, semântica e sincronização da comunicação.\n",
        "\n",
        "---\n",
        "\n",
        "| Protocolo | Descrição |\n",
        "|--|--|\n",
        "| IP | [Internet Protocol](https://pt.wikipedia.org/wiki/Internet_Protocol \"Internet Protocol\") |\n",
        "| HTTP | [Hypertext Transfer Protocol](https://pt.wikipedia.org/wiki/HTTP \"HTTP\") |\n",
        "| POP3 | [Post Office Protocol](https://pt.wikipedia.org/wiki/Post_Office_Protocol \"Post Office Protocol\") |\n",
        "| SMTP | [Simple Mail Transfer Protocol](https://pt.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol \"Simple Mail Transfer Protocol\") |\n"
      ]
    },
    {
      "metadata": {
        "id": "Hi2gErwm2kx7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyDICOM"
      ]
    },
    {
      "metadata": {
        "id": "Ejo1XQc49qfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/pgiaeinstein/aula-09/raw/master/img1.dcm\"\n",
        "!wget \"https://github.com/pgiaeinstein/aula-09/raw/master/img2.dcm\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "528U4dMC3NUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# É necessário instalar o pacote pydicom pelo gerenciador de pacotes pip\n",
        "!pip install pydicom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eH5vxT9w2kHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Após isso, podemos importar o pacote\n",
        "import pydicom\n",
        "import pylab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNuZGTj82f2N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dcmdata = pydicom.read_file('./img1.dcm')\n",
        "print(dcmdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaofMvxVbwnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dcmimg = dcmdata.pixel_array\n",
        "print(dcmimg.dtype)\n",
        "print(dcmimg.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uo8BULvnbywx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(dcmimg, cmap=pylab.cm.binary)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJ0vLl5r-Wtg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Desafio\n",
        "\n",
        "Repita o processo acima para o arquivo img2.dcm"
      ]
    },
    {
      "metadata": {
        "id": "iZgdINAfqxQ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rcU-uqpiq2bi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95LSTFfNq-BZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sobel"
      ]
    },
    {
      "metadata": {
        "id": "N273wgh3xGko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget \"https://res.cloudinary.com/demo/image/upload/e_grayscale/happy_dog.jpg\"\n",
        "! wget \"https://images.freeimages.com/images/large-previews/308/grayscale-rose-1478187.jpg\"\n",
        "! wget \"https://openclipart.org/image/2400px/svg_to_png/225455/Carl-Georg-Adolph-Hasenpflug-Medieval-Town-Grayscale.png\"\n",
        "! wget \"http://floodplanuk.org/wp-content/uploads/2018/08/Images.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6avSN6s-wRTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.style.use('fivethirtyeight')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mplimg\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib as tfcontrib\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2YH3j9YxffR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sobel_img_1 = './happy_dog.jpg'\n",
        "sobel_img_2 = './grayscale-rose-1478187.jpg'\n",
        "sobel_img_3 = './Carl-Georg-Adolph-Hasenpflug-Medieval-Town-Grayscale.png'\n",
        "sobel_img_4 = './Images.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjWDNNmDxwKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def aplica_sobel(imagem):\n",
        "  \n",
        "    img = cv2.imread(imagem, 0)\n",
        "  \n",
        "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
        "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
        "    sobel_g = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "    sobel_g *= 255.0 / np.max(sobel_g)\n",
        "\n",
        "    plt.figure(1, figsize = (15, 15))\n",
        "    plt.subplot(221),plt.imshow(img, cmap = 'gray')\n",
        "    plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(222),plt.imshow(sobel_x, cmap = 'gray')\n",
        "    plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(223),plt.imshow(sobel_y, cmap = 'gray')\n",
        "    plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(224),plt.imshow(sobel_g, cmap = 'gray')\n",
        "    plt.title('Sobel G'), plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2IsTW1wx_an",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aplica_sobel(sobel_img_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BalMvtryaWm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Desafio\n",
        "\n",
        "Tente aplicar o filtro sobel nas imagens `sobel_img_2`. `sobel_img_3` e `sobel_img_4`."
      ]
    },
    {
      "metadata": {
        "id": "fiQUurUzybpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l5s1XpwOyeUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xkp5JGPiyhZf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RaQviU9twJrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "\n",
        "O objetivo desta atividade é familiarizar o aluno com uma CNN. Iremos utilizar o dataset __MNIST__ para treinar uma CNN para classificar números manuscritos."
      ]
    },
    {
      "metadata": {
        "id": "k_a5I_VW0Ic5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D \n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdGGpVJO0NUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "nb_classes = 10\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8aKxOiLa2OAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos exibir algumas imagens deste dataset"
      ]
    },
    {
      "metadata": {
        "id": "iJBVwmju1df4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i])\n",
        "#     plt.imshow(X_train[i, :, :, 0])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PxQ8S6D0cRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-PqXto3i0qot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_filters = 32\n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2, 2)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(nb_filters, kernel_size, padding='valid', input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(nb_filters, kernel_size))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPyDe3Kx0p33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9yreCG6S3XmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mostrar_erros(predictions, trueclass=None, predictedclass=None, maxtoshow=10):\n",
        "   \n",
        "    rounded = np.argmax(predictions, axis=1)\n",
        "    errors = rounded!=y_test\n",
        "\n",
        "    ii = 0\n",
        "    plt.figure(figsize=(maxtoshow, 1))\n",
        "    for i in range(X_test.shape[0]):\n",
        "        if ii>=maxtoshow:\n",
        "            break\n",
        "        if errors[i]:\n",
        "            if trueclass is not None and y_test[i] != trueclass:\n",
        "                continue\n",
        "            if predictedclass is not None and predictions[i] != predictedclass:\n",
        "                continue\n",
        "            plt.subplot(1, maxtoshow, ii+1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(X_test[i,:,:,0], cmap=\"gray\")\n",
        "            plt.title(\"%d (%d)\" % (rounded[i], y_test[i]))\n",
        "            ii = ii + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILxQNq4u5aJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)\n",
        "\n",
        "mostrar_erros(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqjQl3-D5gre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mostrar_erros(preds, trueclass = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlA4lpc2wKDf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kmeans\n",
        "\n",
        "Em nossa próxima atividade, vamos tentar segmentar uma imagem utilizando uma U-Net.\n",
        "\n",
        "Para possibilitar o treinamento desta rede, precisamos criar máscaras de segmentação, ou seja, o que esperamos que a rede responda quando receber uma imagem para analisar.\n",
        "\n",
        "Uma forma simples de fazer isso é aplicar K-means."
      ]
    },
    {
      "metadata": {
        "id": "IDGWYefS7pe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/pgiaeinstein/aula-10/raw/master/original_imgs.zip\"\n",
        "!unzip original_imgs.zip\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ExgjGvbb70KE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def label_para_pixel(bloco, labels, l, a):\n",
        "    dimensao = bloco.shape[1]\n",
        "    imagem = np.zeros((l, a, dimensao))\n",
        "    index = 0\n",
        "        \n",
        "    if bloco[0][0] > bloco[1][0]:\n",
        "        cor_cell = [1., 1., 1.]\n",
        "        cor_fundo = [0., 0., 0.]\n",
        "    else:\n",
        "        cor_cell = [0., 0., 0.]\n",
        "        cor_fundo = [1., 1., 1.]\n",
        "    \n",
        "    for i in range(l):\n",
        "        for j in range(a):\n",
        "            if labels[index] == 0:\n",
        "                imagem[i][j] = cor_fundo\n",
        "            else:\n",
        "                imagem[i][j] = cor_cell\n",
        "            index += 1\n",
        "    return imagem\n",
        "\n",
        "def retorna_kmeans(n_cores, img_path):\n",
        "    \n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img = np.array(img, dtype = np.float64) / 255\n",
        "\n",
        "    w, h, d = tuple(img.shape)\n",
        "    assert d == 3\n",
        "    image_array = np.reshape(img, (w * h, d))\n",
        "\n",
        "    kmeans = KMeans(n_clusters = n_cores, random_state = 0).fit(image_array)\n",
        "    labels = kmeans.predict(image_array)\n",
        "    img_mask = label_para_pixel(kmeans.cluster_centers_, labels, w, h)\n",
        "    return img, img_rgb, img_mask\n",
        "    \n",
        "    \n",
        "def plota_imagens(img, img_mask):\n",
        "    plt.figure(1, figsize = (15, 15))\n",
        "    ax1 = plt.subplot(121)\n",
        "    ax1.axis('off')\n",
        "    ax1.set_title('Imagem original')\n",
        "    ax1.imshow(img)\n",
        "\n",
        "    ax2 = plt.subplot(122)\n",
        "    ax2.axis('off')\n",
        "    ax2.set_title('Imagem K-Means')\n",
        "    ax2.imshow(img_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROTIXOPVlSpw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos imprimir o resultado da clusterização de uma imagem:"
      ]
    },
    {
      "metadata": {
        "id": "EUcQAoXQ8NvF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = './original_imgs/BloodImage_00002.jpg'\n",
        "\n",
        "img, img_rgb, img_mask = retorna_kmeans(2, img)\n",
        "plota_imagens(img_rgb, img_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moIVc3bDljMw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos automatizar a criação de nossa base de treino e teste.\n",
        "\n",
        "A função abaixo percorrerá todo o conteúdo da pasta de imagens original e aplicará o processo de clusterização separando em imagem original e máscara criada em duas pastas distintas para facilitar o _import_ dos dados no exercício futuro."
      ]
    },
    {
      "metadata": {
        "id": "6Je0hsXs8Z4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import errno\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMAGENS_PATH = './imgs'\n",
        "MASKS_PATH = './masks'\n",
        "\n",
        "WORK_PATH = './original_imgs'\n",
        "\n",
        "try:\n",
        "    os.makedirs(IMAGENS_PATH)\n",
        "    os.makedirs(MASKS_PATH)\n",
        "except OSError as e:\n",
        "    if e.errno != errno.EEXIST:\n",
        "        raise\n",
        "        \n",
        "lista_imagens = os.listdir(WORK_PATH)\n",
        "\n",
        "for imagem in tqdm(lista_imagens):\n",
        "    img_nome = imagem.replace('.jpg', '')\n",
        "    img, _, img_mask = retorna_kmeans(2, os.path.join(WORK_PATH, imagem))\n",
        "    cv2.imwrite(os.path.join(IMAGENS_PATH, '{0}.jpg'.format(img_nome)), img * 255)\n",
        "    cv2.imwrite(os.path.join(MASKS_PATH, '{0}_mask.jpg'.format(img_nome)), img_mask * 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2olS1SNOwKWH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "\n",
        "Vamos implementar uma U-Net e nosso objetivo é conseguir segmentar as imagens de células sanguíneas que processamos no exemplo anterior."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wT1kb3q0ghhi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_dir = './imgs'\n",
        "label_dir = './masks'\n",
        "\n",
        "X_train_imgs = os.listdir(img_dir)\n",
        "y_train_imgs = os.listdir(label_dir)\n",
        "\n",
        "for index, img_path in enumerate(X_train_imgs):\n",
        "    X_train_imgs[index] = os.path.join(img_dir, img_path)\n",
        "    \n",
        "for index, img_path in enumerate(y_train_imgs):\n",
        "    y_train_imgs[index] = os.path.join(label_dir, img_path)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntAOhKlDn0wL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos separar nossa base em treino e teste:"
      ]
    },
    {
      "metadata": {
        "id": "eEPtu8inc84I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "tam_test = 0.2\n",
        "\n",
        "X_train_imgs, X_test_imgs, y_train_imgs, y_test_imgs = train_test_split(X_train_imgs, \n",
        "                                                                        y_train_imgs, \n",
        "                                                                        test_size = tam_test, \n",
        "                                                                        random_state = seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HieQu5uc84U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qtd_train_imgs = len(X_train_imgs)\n",
        "qtd_test_imgs = len(X_test_imgs)\n",
        "\n",
        "print(\"Quantidade de imagens para treino: {0}\".format(qtd_train_imgs))\n",
        "print(\"Quantidade de imagens para validação: {0}\".format(qtd_test_imgs))\n",
        "print(\"Quantidade total de imagens: {0}\".format(qtd_train_imgs + qtd_test_imgs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11zYxY4foAIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir algumas imagens para verificar se não há nada de errado até aqui:"
      ]
    },
    {
      "metadata": {
        "id": "BG4viY6Dc84e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qtd_imgs_plot = 5\n",
        "\n",
        "random_imgs = np.random.choice(qtd_train_imgs, qtd_imgs_plot)\n",
        "\n",
        "plt.figure(figsize=(10, 20))\n",
        "\n",
        "for i in range(0, qtd_imgs_plot * 2, 2):\n",
        "    \n",
        "    img_index = random_imgs[i // 2]\n",
        "    X_path = X_train_imgs[img_index]\n",
        "    y_path = y_train_imgs[img_index]\n",
        "\n",
        "    plt.subplot(qtd_imgs_plot, 2, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(mplimg.imread(X_path))\n",
        "    plt.title(\"Imagem original\")\n",
        "\n",
        "    img_mask = Image.open(y_path)\n",
        "    # mask_mtx = np.unique(img_mask)\n",
        "\n",
        "    plt.subplot(qtd_imgs_plot, 2, i + 2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img_mask)\n",
        "    plt.title(\"Máscara da imagem\")  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIdAVatToKHG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos criar um _pipeline_ (uma série de procedimentos que deverá ser respeitado pelo modelo) para treino.\n",
        "\n",
        "Aqui vamos implementar funções que nos permitem aplicar _image augmentation_ em nossa base."
      ]
    },
    {
      "metadata": {
        "id": "Tjetpmzxc84r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = (256, 256, 3)\n",
        "batch_size = 3\n",
        "epochs = 5\n",
        "\n",
        "def proc_img(img_path, mask_path):\n",
        "    \n",
        "    _img = tf.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(_img, channels = 3)\n",
        "\n",
        "    _mask_img = tf.read_file(mask_path)\n",
        "    mask_img = tf.image.decode_gif(_mask_img)[0]\n",
        "    mask_img = mask_img[:, :, 0]\n",
        "    mask_img = tf.expand_dims(mask_img, axis = -1)\n",
        "    \n",
        "    return img, mask_img\n",
        "\n",
        "def shift_img(output_img, mask_img, width_shift_range, height_shift_range):\n",
        "    if width_shift_range or height_shift_range:\n",
        "        if width_shift_range:\n",
        "            width_shift_range = tf.random_uniform([], -width_shift_range * img_shape[1],\n",
        "                                                  width_shift_range * img_shape[1])\n",
        "        if height_shift_range:\n",
        "            height_shift_range = tf.random_uniform([], -height_shift_range * img_shape[0],\n",
        "                                                   height_shift_range * img_shape[0])\n",
        "        output_img = tfcontrib.image.translate(output_img, [width_shift_range, height_shift_range])\n",
        "        mask_img = tfcontrib.image.translate(mask_img, [width_shift_range, height_shift_range])\n",
        "    \n",
        "    return output_img, mask_img\n",
        "\n",
        "def flip_img(horizontal_flip, tr_img, mask_img):\n",
        "    if horizontal_flip:\n",
        "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
        "        tr_img, mask_img = tf.cond(tf.less(flip_prob, 0.5),\n",
        "                                lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(mask_img)),\n",
        "                                lambda: (tr_img, mask_img))\n",
        "    return tr_img, mask_img\n",
        "\n",
        "def augment_img(img, mask_img, resize = None, scale = 1, hue_delta = 0, horizontal_flip = False,\n",
        "             width_shift_range = 0, height_shift_range = 0):\n",
        "    \n",
        "    if resize is not None:\n",
        "        mask_img = tf.image.resize_images(mask_img, resize)\n",
        "        img = tf.image.resize_images(img, resize)\n",
        "\n",
        "    if hue_delta:\n",
        "        img = tf.image.random_hue(img, hue_delta)\n",
        "\n",
        "    img, mask_img = flip_img(horizontal_flip, img, mask_img)\n",
        "    img, mask_img = shift_img(img, mask_img, width_shift_range, height_shift_range)\n",
        "    mask_img = tf.to_float(mask_img) * scale\n",
        "    img = tf.to_float(img) * scale\n",
        "    \n",
        "    return img, mask_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkp50_c7c842",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_baseline_dataset(filenames, labels, preproc_fn = functools.partial(augment_img), threads = 5, \n",
        "                         batch_size = batch_size, shuffle = True):           \n",
        "    num_x = len(filenames)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    dataset = dataset.map(proc_img, num_parallel_calls=threads)\n",
        "    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
        "        assert batch_size == 1, \"Imagens no batch não respeitam as mesmas dimensões\"\n",
        "\n",
        "    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(num_x)\n",
        "\n",
        "\n",
        "    dataset = dataset.repeat().batch(batch_size)\n",
        "    return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXx-vwu8c85B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_cfg = {\n",
        "    'resize': [img_shape[0], img_shape[1]],\n",
        "    'scale': 1 / 255.,\n",
        "    'hue_delta': 0.1,\n",
        "    'horizontal_flip': True,\n",
        "    'width_shift_range': 0.1,\n",
        "    'height_shift_range': 0.1\n",
        "}\n",
        "\n",
        "train_preproc_function = functools.partial(augment_img, **train_cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3jv6BXTCc85Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_cfg = {\n",
        "    'resize': [img_shape[0], img_shape[1]],\n",
        "    'scale': 1 / 255.,\n",
        "}\n",
        "\n",
        "test_preproc_function = functools.partial(augment_img, **test_cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1A7R5ZIMc85a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = get_baseline_dataset(X_train_imgs, y_train_imgs,\n",
        "                                preproc_fn = train_preproc_function, batch_size = batch_size)\n",
        "\n",
        "test_dataset = get_baseline_dataset(X_test_imgs, y_test_imgs, \n",
        "                              preproc_fn = test_preproc_function, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOhpR4kdor1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir uma imagem de exemplo para verificar se nosso processo de _image augmentation_ está funcionando de maneira adequada:"
      ]
    },
    {
      "metadata": {
        "id": "0lDUd-8lc85n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tmp_dataset = get_baseline_dataset(X_train_imgs, y_train_imgs, preproc_fn = train_preproc_function,\n",
        "                               batch_size = 1, shuffle = False)\n",
        "\n",
        "img_aug_iterator = tmp_dataset.make_one_shot_iterator()\n",
        "img_aug_prox = img_aug_iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "    imgs_batch, _y = sess.run(img_aug_prox)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    img = imgs_batch[0]\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(_y[0, :, :, 0])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5uaoKiOo2kn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos definir funções auxiliares para facilitar a construção do modelo:"
      ]
    },
    {
      "metadata": {
        "id": "zCaoaYCwc85y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_block(tensor_entrada, qtd_filtros):\n",
        "    encoder = layers.Conv2D(qtd_filtros, (3, 3), padding = 'same')(tensor_entrada)\n",
        "    encoder = layers.BatchNormalization()(encoder)\n",
        "    encoder = layers.Activation('relu')(encoder)\n",
        "    encoder = layers.Conv2D(qtd_filtros, (3, 3), padding = 'same')(encoder)\n",
        "    encoder = layers.BatchNormalization()(encoder)\n",
        "    encoder = layers.Activation('relu')(encoder)\n",
        "    return encoder\n",
        "\n",
        "def encoder_block(tensor_entrada, qtd_filtros):\n",
        "    encoder = conv_block(tensor_entrada, qtd_filtros)\n",
        "    encoder_pool = layers.MaxPooling2D((2, 2), strides = (2, 2))(encoder)\n",
        "\n",
        "    return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(tensor_entrada, tensor_merge, qtd_filtros):\n",
        "    decoder = layers.Conv2DTranspose(qtd_filtros, (2, 2), strides = (2, 2), padding = 'same')(tensor_entrada)\n",
        "    decoder = layers.concatenate([tensor_merge, decoder], axis = -1)\n",
        "    decoder = layers.BatchNormalization()(decoder)\n",
        "    decoder = layers.Activation('relu')(decoder)\n",
        "    decoder = layers.Conv2D(qtd_filtros, (3, 3), padding = 'same')(decoder)\n",
        "    decoder = layers.BatchNormalization()(decoder)\n",
        "    decoder = layers.Activation('relu')(decoder)\n",
        "    decoder = layers.Conv2D(qtd_filtros, (3, 3), padding = 'same')(decoder)\n",
        "    decoder = layers.BatchNormalization()(decoder)\n",
        "    decoder = layers.Activation('relu')(decoder)\n",
        "    return decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9yPU24sAc85_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = img_shape)\n",
        "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
        "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
        "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
        "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
        "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "center = conv_block(encoder4_pool, 1024)\n",
        "decoder4 = decoder_block(center, encoder4, 512)\n",
        "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
        "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
        "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
        "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
        "outputs = layers.Conv2D(1, (1, 1), activation = 'sigmoid')(decoder0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjJK_-iCc86M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.Model(inputs = [inputs], outputs = [outputs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lvUaTvvo-ro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos definir nossas funções de _loss_:"
      ]
    },
    {
      "metadata": {
        "id": "6UxVB4TXc86Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exDjJDRZc86j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = bce_dice_loss, metrics = [dice_loss])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DCeCkPMlc86t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = './modelo_bc_V1.hdf5'\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = model_path, \n",
        "                                        monitor = 'val_dice_loss', \n",
        "                                        save_best_only = True, \n",
        "                                        verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "ZPnyy-Ync861",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch = int(np.ceil(qtd_train_imgs / float(batch_size))),\n",
        "                    epochs = epochs,\n",
        "                    validation_data = test_dataset,\n",
        "                    validation_steps = int(np.ceil(qtd_test_imgs / float(batch_size))),\n",
        "                    callbacks = [model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Juzc0JLOc86_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dice = history.history['dice_loss']\n",
        "val_dice_loss = history.history['val_dice_loss']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "qtd_epochs = range(epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRqTMoqLc87I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(qtd_epochs, dice, label = 'Dice Loss - Treinamento')\n",
        "plt.plot(qtd_epochs, val_dice_loss, label = 'Dice Loss - Validação')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Dice Loss - Treino e Validação')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(qtd_epochs, loss, label = 'Loss - Treinamento')\n",
        "plt.plot(qtd_epochs, val_loss, label = 'Loss - Validação')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss - Treino e Validação')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9o5qjmktc87R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.load_model(model_path, custom_objects={'bce_dice_loss': bce_dice_loss,\n",
        "                                                      'dice_loss': dice_loss})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TF-NVL8lc87c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_aug_iterator = test_dataset.make_one_shot_iterator()\n",
        "img_aug_prox = img_aug_iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhjUY2Gzc87n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(6):\n",
        "    batch_of_imgs, label = tf.keras.backend.get_session().run(img_aug_prox)\n",
        "    img = batch_of_imgs[0]\n",
        "    predicted_label = model.predict(batch_of_imgs)[0]\n",
        "\n",
        "    plt.subplot(6, 3, 3 * i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Imagem de entrada\")\n",
        "\n",
        "    plt.subplot(6, 3, 3 * i + 2)\n",
        "    plt.imshow(label[0, :, :, 0])\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Máscara real\")\n",
        "    plt.subplot(6, 3, 3 * i + 3)\n",
        "    plt.imshow(predicted_label[:, :, 0])\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Output do modelo\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}